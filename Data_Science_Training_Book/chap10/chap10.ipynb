{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81399896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%.3f'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "%precision 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09525cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores: [0.904 0.912 0.956 0.939 0.956]\n",
      "Cross validation scores: 0.933+-0.022\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# cross_val_score 함수를 통해 k-fold 결과를 확인 가능\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "tree = DecisionTreeClassifier(criterion = 'entropy', max_depth = 3, random_state = 0)\n",
    "\n",
    "# 여기서 cross_val_score 함수의 파라미터는 순서대로 적용할 알고리즘, 설명 변수, 목표 변수, k의 수(cv 값에 해당)\n",
    "# cross_val_score 함수는 5개의 점수(여기서는 정확도)를 ndarray 형태로 반환\n",
    "scores = cross_val_score(tree, cancer.data, cancer.target, cv = 5)\n",
    "\n",
    "# 모델을 선택할 때는, 기본적으로 k-fold 결과 점수의 평균이 높은 모델을 선택\n",
    "# 표준편차가 큰 경우, 평균 점수에서 표준편차를 뺀 값을 기준으로 모델을 선택하기도 함\n",
    "print(f\"Cross validation scores: {scores}\")\n",
    "print(f\"Cross validation scores: {scores.mean():.3f}+-{scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18a604c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------LogisticRegression------------------\n",
      "Cross validation scores: [0.939 0.939 0.974 0.947 0.965]\n",
      "Cross validation scores: 0.953 +- 0.014\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\semin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\semin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\semin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------LinearSVC------------------\n",
      "Cross validation scores: [0.895 0.939 0.93  0.842 0.947]\n",
      "Cross validation scores: 0.910 +- 0.039\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\semin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\semin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 연습 문제 10-1\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "logistic = LogisticRegression(random_state = 0, max_iter = 100, solver='liblinear')\n",
    "svm = LinearSVC(max_iter = 10000)\n",
    "\n",
    "for model in [logistic, svm]:\n",
    "    scores = cross_val_score(model, cancer.data, cancer.target, cv=5)\n",
    "    print(f\"------------------{model.__class__.__name__}------------------\")\n",
    "    print(f\"Cross validation scores: {scores}\")\n",
    "    print(f\"Cross validation scores: {scores.mean():.3f} +- {scores.std():.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3f4901f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최고 점수: 0.91\n",
      "최고 점수에서의 하이퍼파라미터(gamma, C): (0.001, 1.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='C', ylabel='gamma'>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(cancer.data, cancer.target, test_size = 0.5,\n",
    "                                                    stratify = cancer.target, random_state = 0)\n",
    "\n",
    "# 점수들을 딕셔너리로 저장\n",
    "scores={}\n",
    "\n",
    "for gamma in np.logspace(-3, 2, 6):\n",
    "    for C in np.logspace(-3, 2, 6):\n",
    "        svm = SVC(gamma=gamma, C=C)\n",
    "        svm.fit(X_train, Y_train)\n",
    "        scores[(gamma, C)] = svm.score(X_test, Y_test)\n",
    "\n",
    "# max값과 해당 값에서의 조합을 알기 위해 시리즈 객체로 만듦\n",
    "scores = pd.Series(scores)\n",
    "\n",
    "print(f\"최고 점수: {scores.max():.2f}\")\n",
    "print(f\"최고 점수에서의 하이퍼파라미터(gamma, C): {scores.idxmax()}\")\n",
    "\n",
    "a = scores.unstack()\n",
    "a.index.name = 'gamma'\n",
    "a.columns.name = 'C'\n",
    "# 세로축은 gamma, 가로축은 C\n",
    "sns.heatmap(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "00eda7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross validation score: 0.933\n",
      "Best parameters: {'C': 10.0, 'gamma': 0.001}\n",
      "Test score: 0.905\n"
     ]
    }
   ],
   "source": [
    "# 클래스를 사용한 그리드 서치 실행\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.5,\n",
    "                                                   stratify = cancer.target, random_state=0)\n",
    "\n",
    "# GridSearchCV 클래스에 전달할 파라미터 값 지정\n",
    "param_grid = {'C': np.logspace(-3, 2, 6), 'gamma': np.logspace(-3,2,6)}\n",
    "\n",
    "# GridSearchCV 클래스 초기화\n",
    "# fit 메소드 실행 시 k-fold에서 조금 더 개선된 방법을 이용\n",
    "gs = GridSearchCV(estimator=SVC(), param_grid = param_grid, cv=5)\n",
    "\n",
    "# 모든 하이퍼파라미터 조합으로 모델 검증 및 베스트 모델 구축\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best cross validation score: {gs.best_score_:.3f}')\n",
    "print(f'Best parameters: {gs.best_params_}')\n",
    "print(f'Test score: {gs.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "24eca6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.933\n",
      "0.905\n"
     ]
    }
   ],
   "source": [
    "test = SVC(gamma = 0.001, C = 10.0)\n",
    "scores = cross_val_score(test, X_train, y_train, cv=5)\n",
    "print(f'{scores.mean():.3f}')\n",
    "test.fit(X_train, y_train)\n",
    "print(f'{test.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d4c4bcdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003672</td>\n",
       "      <td>2.865500e-03</td>\n",
       "      <td>0.001064</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.001}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002986</td>\n",
       "      <td>2.325509e-05</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.01}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004808</td>\n",
       "      <td>5.798849e-03</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.1}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006003</td>\n",
       "      <td>6.334892e-03</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 0.001, 'gamma': 1.0}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000601</td>\n",
       "      <td>1.202202e-03</td>\n",
       "      <td>0.006798</td>\n",
       "      <td>0.008326</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'C': 0.001, 'gamma': 10.0}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.005883</td>\n",
       "      <td>7.037733e-03</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>{'C': 0.001, 'gamma': 100.0}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003794</td>\n",
       "      <td>7.096749e-03</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.001}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000402</td>\n",
       "      <td>8.049011e-04</td>\n",
       "      <td>0.006364</td>\n",
       "      <td>0.007796</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.01}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001001</td>\n",
       "      <td>1.551113e-03</td>\n",
       "      <td>0.003437</td>\n",
       "      <td>0.006875</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.1}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.007333</td>\n",
       "      <td>8.982866e-03</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 0.01, 'gamma': 1.0}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.004185</td>\n",
       "      <td>5.874965e-03</td>\n",
       "      <td>0.003482</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'C': 0.01, 'gamma': 10.0}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.004021</td>\n",
       "      <td>6.631145e-03</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100.0</td>\n",
       "      <td>{'C': 0.01, 'gamma': 100.0}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.004305</td>\n",
       "      <td>5.993141e-03</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.001}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001002</td>\n",
       "      <td>1.266787e-03</td>\n",
       "      <td>0.004935</td>\n",
       "      <td>0.006531</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.01}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.007382</td>\n",
       "      <td>9.088588e-03</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.1}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.004132</td>\n",
       "      <td>5.946185e-03</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.002542</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 0.1, 'gamma': 1.0}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.003816</td>\n",
       "      <td>6.671666e-03</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'C': 0.1, 'gamma': 10.0}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.004070</td>\n",
       "      <td>7.651859e-03</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>0.006705</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>{'C': 0.1, 'gamma': 100.0}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.006220</td>\n",
       "      <td>5.461994e-03</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 1.0, 'gamma': 0.001}</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.926253</td>\n",
       "      <td>0.033915</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.006083</td>\n",
       "      <td>3.823020e-03</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1.0, 'gamma': 0.01}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.005982</td>\n",
       "      <td>1.284649e-03</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 1.0, 'gamma': 0.1}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.004878</td>\n",
       "      <td>1.854885e-04</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0, 'gamma': 1.0}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.005045</td>\n",
       "      <td>2.619747e-04</td>\n",
       "      <td>0.002161</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'C': 1.0, 'gamma': 10.0}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.004996</td>\n",
       "      <td>4.333713e-06</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>{'C': 1.0, 'gamma': 100.0}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.003445</td>\n",
       "      <td>3.573318e-04</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 10.0, 'gamma': 0.001}</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.933271</td>\n",
       "      <td>0.030082</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.004454</td>\n",
       "      <td>4.321070e-04</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 10.0, 'gamma': 0.01}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.004801</td>\n",
       "      <td>4.052981e-04</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 10.0, 'gamma': 0.1}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.005001</td>\n",
       "      <td>1.907349e-07</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 10.0, 'gamma': 1.0}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.005207</td>\n",
       "      <td>1.747198e-04</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'C': 10.0, 'gamma': 10.0}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.004999</td>\n",
       "      <td>5.253871e-06</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>{'C': 10.0, 'gamma': 100.0}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.005154</td>\n",
       "      <td>6.756446e-03</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 100.0, 'gamma': 0.001}</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.933271</td>\n",
       "      <td>0.030082</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.003277</td>\n",
       "      <td>1.720020e-03</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 100.0, 'gamma': 0.01}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.003796</td>\n",
       "      <td>7.105427e-03</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>0.006786</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 100.0, 'gamma': 0.1}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.003497</td>\n",
       "      <td>4.871509e-03</td>\n",
       "      <td>0.003267</td>\n",
       "      <td>0.006535</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 100.0, 'gamma': 1.0}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.004562</td>\n",
       "      <td>6.416325e-03</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'C': 100.0, 'gamma': 10.0}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.003947</td>\n",
       "      <td>7.045420e-03</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>{'C': 100.0, 'gamma': 100.0}</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.626754</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.003672  2.865500e-03         0.001064        0.000972   0.001   \n",
       "1        0.002986  2.325509e-05         0.002018        0.000028   0.001   \n",
       "2        0.004808  5.798849e-03         0.000674        0.000606   0.001   \n",
       "3        0.006003  6.334892e-03         0.000199        0.000398   0.001   \n",
       "4        0.000601  1.202202e-03         0.006798        0.008326   0.001   \n",
       "5        0.005883  7.037733e-03         0.000810        0.001169   0.001   \n",
       "6        0.003794  7.096749e-03         0.000135        0.000269    0.01   \n",
       "7        0.000402  8.049011e-04         0.006364        0.007796    0.01   \n",
       "8        0.001001  1.551113e-03         0.003437        0.006875    0.01   \n",
       "9        0.007333  8.982866e-03         0.000609        0.000805    0.01   \n",
       "10       0.004185  5.874965e-03         0.003482        0.006270    0.01   \n",
       "11       0.004021  6.631145e-03         0.000200        0.000400    0.01   \n",
       "12       0.004305  5.993141e-03         0.000402        0.000493     0.1   \n",
       "13       0.001002  1.266787e-03         0.004935        0.006531     0.1   \n",
       "14       0.007382  9.088588e-03         0.000600        0.000800     0.1   \n",
       "15       0.004132  5.946185e-03         0.001770        0.002542     0.1   \n",
       "16       0.003816  6.671666e-03         0.000441        0.000881     0.1   \n",
       "17       0.004070  7.651859e-03         0.003353        0.006705     0.1   \n",
       "18       0.006220  5.461994e-03         0.001402        0.000489     1.0   \n",
       "19       0.006083  3.823020e-03         0.000399        0.000488     1.0   \n",
       "20       0.005982  1.284649e-03         0.001477        0.000869     1.0   \n",
       "21       0.004878  1.854885e-04         0.002154        0.000169     1.0   \n",
       "22       0.005045  2.619747e-04         0.002161        0.000199     1.0   \n",
       "23       0.004996  4.333713e-06         0.002005        0.000004     1.0   \n",
       "24       0.003445  3.573318e-04         0.001236        0.000283    10.0   \n",
       "25       0.004454  4.321070e-04         0.002018        0.000030    10.0   \n",
       "26       0.004801  4.052981e-04         0.002075        0.000154    10.0   \n",
       "27       0.005001  1.907349e-07         0.002092        0.000183    10.0   \n",
       "28       0.005207  1.747198e-04         0.001795        0.000179    10.0   \n",
       "29       0.004999  5.253871e-06         0.001803        0.000394    10.0   \n",
       "30       0.005154  6.756446e-03         0.000360        0.000720   100.0   \n",
       "31       0.003277  1.720020e-03         0.001279        0.001054   100.0   \n",
       "32       0.003796  7.105427e-03         0.003393        0.006786   100.0   \n",
       "33       0.003497  4.871509e-03         0.003267        0.006535   100.0   \n",
       "34       0.004562  6.416325e-03         0.000634        0.000859   100.0   \n",
       "35       0.003947  7.045420e-03         0.000321        0.000641   100.0   \n",
       "\n",
       "   param_gamma                        params  split0_test_score  \\\n",
       "0        0.001  {'C': 0.001, 'gamma': 0.001}           0.631579   \n",
       "1         0.01   {'C': 0.001, 'gamma': 0.01}           0.631579   \n",
       "2          0.1    {'C': 0.001, 'gamma': 0.1}           0.631579   \n",
       "3          1.0    {'C': 0.001, 'gamma': 1.0}           0.631579   \n",
       "4         10.0   {'C': 0.001, 'gamma': 10.0}           0.631579   \n",
       "5        100.0  {'C': 0.001, 'gamma': 100.0}           0.631579   \n",
       "6        0.001   {'C': 0.01, 'gamma': 0.001}           0.631579   \n",
       "7         0.01    {'C': 0.01, 'gamma': 0.01}           0.631579   \n",
       "8          0.1     {'C': 0.01, 'gamma': 0.1}           0.631579   \n",
       "9          1.0     {'C': 0.01, 'gamma': 1.0}           0.631579   \n",
       "10        10.0    {'C': 0.01, 'gamma': 10.0}           0.631579   \n",
       "11       100.0   {'C': 0.01, 'gamma': 100.0}           0.631579   \n",
       "12       0.001    {'C': 0.1, 'gamma': 0.001}           0.631579   \n",
       "13        0.01     {'C': 0.1, 'gamma': 0.01}           0.631579   \n",
       "14         0.1      {'C': 0.1, 'gamma': 0.1}           0.631579   \n",
       "15         1.0      {'C': 0.1, 'gamma': 1.0}           0.631579   \n",
       "16        10.0     {'C': 0.1, 'gamma': 10.0}           0.631579   \n",
       "17       100.0    {'C': 0.1, 'gamma': 100.0}           0.631579   \n",
       "18       0.001    {'C': 1.0, 'gamma': 0.001}           0.947368   \n",
       "19        0.01     {'C': 1.0, 'gamma': 0.01}           0.631579   \n",
       "20         0.1      {'C': 1.0, 'gamma': 0.1}           0.631579   \n",
       "21         1.0      {'C': 1.0, 'gamma': 1.0}           0.631579   \n",
       "22        10.0     {'C': 1.0, 'gamma': 10.0}           0.631579   \n",
       "23       100.0    {'C': 1.0, 'gamma': 100.0}           0.631579   \n",
       "24       0.001   {'C': 10.0, 'gamma': 0.001}           0.947368   \n",
       "25        0.01    {'C': 10.0, 'gamma': 0.01}           0.631579   \n",
       "26         0.1     {'C': 10.0, 'gamma': 0.1}           0.631579   \n",
       "27         1.0     {'C': 10.0, 'gamma': 1.0}           0.631579   \n",
       "28        10.0    {'C': 10.0, 'gamma': 10.0}           0.631579   \n",
       "29       100.0   {'C': 10.0, 'gamma': 100.0}           0.631579   \n",
       "30       0.001  {'C': 100.0, 'gamma': 0.001}           0.947368   \n",
       "31        0.01   {'C': 100.0, 'gamma': 0.01}           0.631579   \n",
       "32         0.1    {'C': 100.0, 'gamma': 0.1}           0.631579   \n",
       "33         1.0    {'C': 100.0, 'gamma': 1.0}           0.631579   \n",
       "34        10.0   {'C': 100.0, 'gamma': 10.0}           0.631579   \n",
       "35       100.0  {'C': 100.0, 'gamma': 100.0}           0.631579   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.631579           0.631579           0.614035   \n",
       "1            0.631579           0.631579           0.614035   \n",
       "2            0.631579           0.631579           0.614035   \n",
       "3            0.631579           0.631579           0.614035   \n",
       "4            0.631579           0.631579           0.614035   \n",
       "5            0.631579           0.631579           0.614035   \n",
       "6            0.631579           0.631579           0.614035   \n",
       "7            0.631579           0.631579           0.614035   \n",
       "8            0.631579           0.631579           0.614035   \n",
       "9            0.631579           0.631579           0.614035   \n",
       "10           0.631579           0.631579           0.614035   \n",
       "11           0.631579           0.631579           0.614035   \n",
       "12           0.631579           0.631579           0.614035   \n",
       "13           0.631579           0.631579           0.614035   \n",
       "14           0.631579           0.631579           0.614035   \n",
       "15           0.631579           0.631579           0.614035   \n",
       "16           0.631579           0.631579           0.614035   \n",
       "17           0.631579           0.631579           0.614035   \n",
       "18           0.912281           0.894737           0.894737   \n",
       "19           0.631579           0.631579           0.614035   \n",
       "20           0.631579           0.631579           0.614035   \n",
       "21           0.631579           0.631579           0.614035   \n",
       "22           0.631579           0.631579           0.614035   \n",
       "23           0.631579           0.631579           0.614035   \n",
       "24           0.912281           0.894737           0.929825   \n",
       "25           0.631579           0.631579           0.614035   \n",
       "26           0.631579           0.631579           0.614035   \n",
       "27           0.631579           0.631579           0.614035   \n",
       "28           0.631579           0.631579           0.614035   \n",
       "29           0.631579           0.631579           0.614035   \n",
       "30           0.912281           0.894737           0.929825   \n",
       "31           0.631579           0.631579           0.614035   \n",
       "32           0.631579           0.631579           0.614035   \n",
       "33           0.631579           0.631579           0.614035   \n",
       "34           0.631579           0.631579           0.614035   \n",
       "35           0.631579           0.631579           0.614035   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.625000         0.626754        0.006851                4  \n",
       "1            0.625000         0.626754        0.006851                4  \n",
       "2            0.625000         0.626754        0.006851                4  \n",
       "3            0.625000         0.626754        0.006851                4  \n",
       "4            0.625000         0.626754        0.006851                4  \n",
       "5            0.625000         0.626754        0.006851                4  \n",
       "6            0.625000         0.626754        0.006851                4  \n",
       "7            0.625000         0.626754        0.006851                4  \n",
       "8            0.625000         0.626754        0.006851                4  \n",
       "9            0.625000         0.626754        0.006851                4  \n",
       "10           0.625000         0.626754        0.006851                4  \n",
       "11           0.625000         0.626754        0.006851                4  \n",
       "12           0.625000         0.626754        0.006851                4  \n",
       "13           0.625000         0.626754        0.006851                4  \n",
       "14           0.625000         0.626754        0.006851                4  \n",
       "15           0.625000         0.626754        0.006851                4  \n",
       "16           0.625000         0.626754        0.006851                4  \n",
       "17           0.625000         0.626754        0.006851                4  \n",
       "18           0.982143         0.926253        0.033915                3  \n",
       "19           0.625000         0.626754        0.006851                4  \n",
       "20           0.625000         0.626754        0.006851                4  \n",
       "21           0.625000         0.626754        0.006851                4  \n",
       "22           0.625000         0.626754        0.006851                4  \n",
       "23           0.625000         0.626754        0.006851                4  \n",
       "24           0.982143         0.933271        0.030082                1  \n",
       "25           0.625000         0.626754        0.006851                4  \n",
       "26           0.625000         0.626754        0.006851                4  \n",
       "27           0.625000         0.626754        0.006851                4  \n",
       "28           0.625000         0.626754        0.006851                4  \n",
       "29           0.625000         0.626754        0.006851                4  \n",
       "30           0.982143         0.933271        0.030082                1  \n",
       "31           0.625000         0.626754        0.006851                4  \n",
       "32           0.625000         0.626754        0.006851                4  \n",
       "33           0.625000         0.626754        0.006851                4  \n",
       "34           0.625000         0.626754        0.006851                4  \n",
       "35           0.625000         0.626754        0.006851                4  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "11c2d39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001CE1B7ADCD0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.933"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, expon, reciprocal\n",
    "print(expon(scale = 4))\n",
    "rs = RandomizedSearchCV(estimator=SVC(), param_distributions = param_grid, cv=5)\n",
    "rs.fit(X_train,y_train)\n",
    "rs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "432e43ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.941313269493844\n",
      "{'max_depth': 4, 'min_samples_leaf': 5}\n",
      "0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "# 연습 문제 10-2\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "param_grid = {'max_depth': [2, 3, 4, 5], 'min_samples_leaf': [2, 3, 4, 5]}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, stratify = cancer.target, random_state=0)\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "gs = GridSearchCV(tree, param_grid=param_grid, cv=5)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "print(gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33570f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[48  5]\n",
      " [ 8 82]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target,\n",
    "                                                    stratify = cancer.target, random_state = 66)\n",
    "\n",
    "model = SVC(gamma = 0.001, C = 1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# confusion_matrix(실제값, 예측값)\n",
    "m = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# 출력 형태는 열은 예측값, 행은 실제값\n",
    "#         | 부정 | 긍정 |\n",
    "#  ――――――――――――――――――――――\n",
    "#  | 부정 |  TN  |  FP  |\n",
    "#  ――――――――――――――――――――――\n",
    "#  | 긍정 |  FN  |  TP  |\n",
    "\n",
    "print(f'Confusion matrix:\\n {m}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a8892d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.909\n",
      "정밀도: 0.943\n",
      "재현율: 0.911\n",
      "F1-score: 0.927\n"
     ]
    }
   ],
   "source": [
    "accuracy = (m[0, 0] + m[1,1]) / m.sum()\n",
    "print(f'정확도: {accuracy:.3f}')\n",
    "\n",
    "precision = m[1][1] / m[:,1].sum()\n",
    "print(f'정밀도: {precision:.3f}')\n",
    "\n",
    "recall = m[1][1] / m[1].sum()\n",
    "print(f'재현율: {recall:.3f}')\n",
    "\n",
    "f1 = 2*precision*recall / (precision + recall)\n",
    "print(f'F1-score: {f1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f769f031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.909\n",
      "정밀도: 0.943\n",
      "재현율: 0.911\n",
      "F1-score: 0.927\n"
     ]
    }
   ],
   "source": [
    "# 사이킷런 함수를 이용해서 구현\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print(f'정확도: {accuracy_score(y_test, y_pred):.3f}')\n",
    "print(f'정밀도: {precision_score(y_test, y_pred):.3f}')\n",
    "print(f'재현율: {recall_score(y_test, y_pred):.3f}')\n",
    "print(f'F1-score: {f1_score(y_test, y_pred):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b822bd7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------LogisticRegression-----------------\n",
      "Confusion Matrix:\n",
      "[[49  4]\n",
      " [ 5 85]]\n",
      "\n",
      "정확도: 0.937\n",
      "정밀도: 0.955\n",
      "재현율: 0.944\n",
      "F1-score: 0.950\n",
      "\n",
      "-----------------DecisionTreeClassifier-----------------\n",
      "Confusion Matrix:\n",
      "[[48  5]\n",
      " [ 9 81]]\n",
      "\n",
      "정확도: 0.902\n",
      "정밀도: 0.942\n",
      "재현율: 0.900\n",
      "F1-score: 0.920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 연습 문제 10-3\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, stratify = cancer.target, random_state=0)\n",
    "\n",
    "logistic = LogisticRegression(random_state=0, max_iter=2500)\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "for model in [logistic, tree]:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f'-----------------{model.__class__.__name__}-----------------')\n",
    "    print(f'Confusion Matrix:\\n{cm}\\n')\n",
    "    print(f'정확도: {accuracy_score(y_test, y_pred):.3f}')\n",
    "    print(f'정밀도: {precision_score(y_test, y_pred):.3f}')\n",
    "    print(f'재현율: {recall_score(y_test, y_pred):.3f}')\n",
    "    print(f'F1-score: {f1_score(y_test, y_pred):.3f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f55546e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>malignant</th>\n",
       "      <th>benign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003753</td>\n",
       "      <td>0.996247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.999475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027698</td>\n",
       "      <td>0.972302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007188</td>\n",
       "      <td>0.992812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003221</td>\n",
       "      <td>0.996779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   malignant    benign\n",
       "0   0.003753  0.996247\n",
       "1   0.000525  0.999475\n",
       "2   0.027698  0.972302\n",
       "3   0.007188  0.992812\n",
       "4   0.003221  0.996779"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "# 여기에서는 악성(malignant)을 0, 양성(benign)을 1로 분류함\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target,\n",
    "                                                    stratify = cancer.target,\n",
    "                                                    random_state=66)\n",
    "\n",
    "model = LogisticRegression(random_state=0, solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# LogisticRegression 클래스의 predict_proba 메소드는 0, 1과 같은 레이블이 아닌\n",
    "# 각 레이블로 분류 될 확률값의 배열을 리턴\n",
    "results = pd.DataFrame(model.predict_proba(X_test), columns=cancer.target_names)\n",
    "print(results.shape)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8758daa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>malignant</th>\n",
       "      <th>benign</th>\n",
       "      <th>flag_0.4</th>\n",
       "      <th>flag_0.3</th>\n",
       "      <th>flag_0.15</th>\n",
       "      <th>flag_0.05</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003753</td>\n",
       "      <td>0.996247</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.999475</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027698</td>\n",
       "      <td>0.972302</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007188</td>\n",
       "      <td>0.992812</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003221</td>\n",
       "      <td>0.996779</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.008857</td>\n",
       "      <td>0.991143</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.006011</td>\n",
       "      <td>0.993989</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003220</td>\n",
       "      <td>0.996780</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.917868</td>\n",
       "      <td>0.082132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.817335</td>\n",
       "      <td>0.182665</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   malignant    benign  flag_0.4  flag_0.3  flag_0.15  flag_0.05\n",
       "0   0.003753  0.996247         1         1          1          1\n",
       "1   0.000525  0.999475         1         1          1          1\n",
       "2   0.027698  0.972302         1         1          1          1\n",
       "3   0.007188  0.992812         1         1          1          1\n",
       "4   0.003221  0.996779         1         1          1          1\n",
       "5   0.008857  0.991143         1         1          1          1\n",
       "6   0.006011  0.993989         1         1          1          1\n",
       "7   0.003220  0.996780         1         1          1          1\n",
       "8   0.917868  0.082132         0         0          0          1\n",
       "9   0.817335  0.182665         0         0          1          1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 임계값을 0.4, 0.3, 0.15, 0.05로 설정한 경우를 생각\n",
    "for threshold in [0.4, 0.3, 0.15, 0.05]:\n",
    "    results[f'flag_{threshold}'] = results['benign'].map(lambda x:1 if x > threshold else 0)\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27e8eda6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='FPR', ylabel='TPR'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 임계값이 0.01, 0.03, 0.05, ..., 0.99인 경우 \n",
    "rates = {}\n",
    "for threshold in np.linspace(0.01, 0.99, num=50):\n",
    "    labels = results['benign'].map(lambda x:1 if x > threshold else 0)\n",
    "    m = confusion_matrix(y_test, labels)\n",
    "    rates[threshold] = {'FPR': m[0,1] / m[0,:].sum(),\n",
    "                        'TPR': m[1,1] / m[1,:].sum()}\n",
    "pd.DataFrame(rates).T.plot.scatter('FPR', 'TPR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c71c65c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.010: {'FPR': 0.264, 'TPR': 1.000},\n",
       " 0.030: {'FPR': 0.208, 'TPR': 1.000},\n",
       " 0.050: {'FPR': 0.208, 'TPR': 0.989},\n",
       " 0.070: {'FPR': 0.189, 'TPR': 0.989},\n",
       " 0.090: {'FPR': 0.170, 'TPR': 0.989},\n",
       " 0.110: {'FPR': 0.170, 'TPR': 0.989},\n",
       " 0.130: {'FPR': 0.170, 'TPR': 0.989},\n",
       " 0.150: {'FPR': 0.170, 'TPR': 0.989},\n",
       " 0.170: {'FPR': 0.170, 'TPR': 0.989},\n",
       " 0.190: {'FPR': 0.151, 'TPR': 0.989},\n",
       " 0.210: {'FPR': 0.151, 'TPR': 0.989},\n",
       " 0.230: {'FPR': 0.151, 'TPR': 0.989},\n",
       " 0.250: {'FPR': 0.151, 'TPR': 0.989},\n",
       " 0.270: {'FPR': 0.151, 'TPR': 0.978},\n",
       " 0.290: {'FPR': 0.132, 'TPR': 0.978},\n",
       " 0.310: {'FPR': 0.113, 'TPR': 0.978},\n",
       " 0.330: {'FPR': 0.113, 'TPR': 0.978},\n",
       " 0.350: {'FPR': 0.113, 'TPR': 0.978},\n",
       " 0.370: {'FPR': 0.113, 'TPR': 0.978},\n",
       " 0.390: {'FPR': 0.094, 'TPR': 0.967},\n",
       " 0.410: {'FPR': 0.094, 'TPR': 0.956},\n",
       " 0.430: {'FPR': 0.094, 'TPR': 0.956},\n",
       " 0.450: {'FPR': 0.094, 'TPR': 0.956},\n",
       " 0.470: {'FPR': 0.094, 'TPR': 0.956},\n",
       " 0.490: {'FPR': 0.094, 'TPR': 0.956},\n",
       " 0.510: {'FPR': 0.094, 'TPR': 0.956},\n",
       " 0.530: {'FPR': 0.075, 'TPR': 0.956},\n",
       " 0.550: {'FPR': 0.075, 'TPR': 0.956},\n",
       " 0.570: {'FPR': 0.075, 'TPR': 0.956},\n",
       " 0.590: {'FPR': 0.075, 'TPR': 0.956},\n",
       " 0.610: {'FPR': 0.075, 'TPR': 0.956},\n",
       " 0.630: {'FPR': 0.075, 'TPR': 0.944},\n",
       " 0.650: {'FPR': 0.075, 'TPR': 0.944},\n",
       " 0.670: {'FPR': 0.075, 'TPR': 0.933},\n",
       " 0.690: {'FPR': 0.075, 'TPR': 0.933},\n",
       " 0.710: {'FPR': 0.057, 'TPR': 0.933},\n",
       " 0.730: {'FPR': 0.057, 'TPR': 0.933},\n",
       " 0.750: {'FPR': 0.057, 'TPR': 0.922},\n",
       " 0.770: {'FPR': 0.057, 'TPR': 0.911},\n",
       " 0.790: {'FPR': 0.057, 'TPR': 0.911},\n",
       " 0.810: {'FPR': 0.057, 'TPR': 0.900},\n",
       " 0.830: {'FPR': 0.057, 'TPR': 0.900},\n",
       " 0.850: {'FPR': 0.057, 'TPR': 0.889},\n",
       " 0.870: {'FPR': 0.057, 'TPR': 0.878},\n",
       " 0.890: {'FPR': 0.038, 'TPR': 0.856},\n",
       " 0.910: {'FPR': 0.038, 'TPR': 0.856},\n",
       " 0.930: {'FPR': 0.038, 'TPR': 0.833},\n",
       " 0.950: {'FPR': 0.038, 'TPR': 0.833},\n",
       " 0.970: {'FPR': 0.038, 'TPR': 0.744},\n",
       " 0.990: {'FPR': 0.000, 'TPR': 0.656}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b67ed2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.03</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.07</th>\n",
       "      <th>0.09</th>\n",
       "      <th>0.11</th>\n",
       "      <th>0.13</th>\n",
       "      <th>0.15</th>\n",
       "      <th>0.17</th>\n",
       "      <th>0.19</th>\n",
       "      <th>...</th>\n",
       "      <th>0.81</th>\n",
       "      <th>0.83</th>\n",
       "      <th>0.85</th>\n",
       "      <th>0.87</th>\n",
       "      <th>0.89</th>\n",
       "      <th>0.91</th>\n",
       "      <th>0.93</th>\n",
       "      <th>0.95</th>\n",
       "      <th>0.97</th>\n",
       "      <th>0.99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FPR</th>\n",
       "      <td>0.264151</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>0.188679</td>\n",
       "      <td>0.169811</td>\n",
       "      <td>0.169811</td>\n",
       "      <td>0.169811</td>\n",
       "      <td>0.169811</td>\n",
       "      <td>0.169811</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.877778</td>\n",
       "      <td>0.855556</td>\n",
       "      <td>0.855556</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>0.655556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0.01      0.03      0.05      0.07      0.09      0.11      0.13  \\\n",
       "FPR  0.264151  0.207547  0.207547  0.188679  0.169811  0.169811  0.169811   \n",
       "TPR  1.000000  1.000000  0.988889  0.988889  0.988889  0.988889  0.988889   \n",
       "\n",
       "         0.15      0.17      0.19  ...      0.81      0.83      0.85  \\\n",
       "FPR  0.169811  0.169811  0.150943  ...  0.056604  0.056604  0.056604   \n",
       "TPR  0.988889  0.988889  0.988889  ...  0.900000  0.900000  0.888889   \n",
       "\n",
       "         0.87      0.89      0.91      0.93      0.95      0.97      0.99  \n",
       "FPR  0.056604  0.037736  0.037736  0.037736  0.037736  0.037736  0.000000  \n",
       "TPR  0.877778  0.855556  0.855556  0.833333  0.833333  0.744444  0.655556  \n",
       "\n",
       "[2 rows x 50 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "878b3fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 사이킷런의 roc_curve 함수를 이용해 roc 곡선 그리기\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target,\n",
    "                                                    random_state=66, test_size=0.5)\n",
    "\n",
    "model = svm.SVC(kernel='linear', probability = True, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_pred)\n",
    "auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color='r', label=f'ROC curve (area={auc:.3f})')\n",
    "plt.plot([0,1], [0, 1], color='black', linestyle='--')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ffb96390",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fpr</th>\n",
       "      <th>tpr</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.999993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>0.999993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.801075</td>\n",
       "      <td>0.875372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.801075</td>\n",
       "      <td>0.862806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.798845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.791412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.776761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.771323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.940860</td>\n",
       "      <td>0.709468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.050505</td>\n",
       "      <td>0.940860</td>\n",
       "      <td>0.700236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fpr       tpr  threshold\n",
       "0  0.000000  0.000000   1.999993\n",
       "1  0.000000  0.005376   0.999993\n",
       "2  0.000000  0.801075   0.875372\n",
       "3  0.010101  0.801075   0.862806\n",
       "4  0.010101  0.887097   0.798845\n",
       "5  0.020202  0.887097   0.791412\n",
       "6  0.020202  0.903226   0.776761\n",
       "7  0.030303  0.903226   0.771323\n",
       "8  0.030303  0.940860   0.709468\n",
       "9  0.050505  0.940860   0.700236"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.concat([pd.DataFrame(fpr), pd.DataFrame(tpr), pd.DataFrame(threshold)], axis=1)\n",
    "a.columns = ['fpr', 'tpr', 'threshold']\n",
    "print(a.shape)\n",
    "a.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e9abd856",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 연습 문제 10-4\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "iris = load_iris()[]\n",
    "y = label_binarize(iris.target, classes=[0,1,2])\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, y, random_state=0, test_size=0.5)\n",
    "\n",
    "model = OneVsRestClassifier(SVC(kernel ='linear', random_state = 0, probability=True))\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_test)\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, color='r', label=f'ROC curve (area={auc:.3f})')\n",
    "plt.plot([0,1], [0,1], color='black', linestyle='--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0, 1.05])\n",
    "plt.legend(loc='best')\n",
    "plt.title('ROC curve')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9cecb18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.166e-03, 3.959e-01, 9.226e-01],\n",
       "       [3.896e-02, 8.235e-01, 2.730e-02],\n",
       "       [9.798e-01, 4.674e-03, 9.381e-05],\n",
       "       [6.041e-04, 2.954e-01, 9.392e-01],\n",
       "       [9.531e-01, 7.977e-02, 9.854e-05],\n",
       "       [9.065e-04, 1.192e-01, 9.908e-01],\n",
       "       [9.669e-01, 5.450e-02, 8.358e-05],\n",
       "       [1.637e-02, 1.541e-01, 2.956e-01],\n",
       "       [1.122e-02, 3.334e-01, 2.385e-01],\n",
       "       [5.222e-02, 3.593e-01, 6.927e-02],\n",
       "       [2.408e-03, 6.657e-01, 7.464e-01],\n",
       "       [2.611e-02, 1.265e-01, 2.696e-01],\n",
       "       [1.666e-02, 4.383e-01, 2.261e-01],\n",
       "       [1.507e-02, 3.439e-01, 2.405e-01],\n",
       "       [1.551e-02, 3.438e-01, 3.287e-01],\n",
       "       [9.695e-01, 4.780e-02, 8.008e-05],\n",
       "       [2.049e-02, 3.294e-01, 2.919e-01],\n",
       "       [2.466e-02, 6.516e-01, 1.741e-01],\n",
       "       [9.402e-01, 2.457e-01, 8.543e-05],\n",
       "       [9.741e-01, 1.147e-02, 9.970e-05],\n",
       "       [6.348e-03, 4.460e-01, 7.925e-01],\n",
       "       [2.319e-02, 3.073e-01, 3.834e-01],\n",
       "       [9.107e-01, 1.035e-01, 2.871e-04],\n",
       "       [9.414e-01, 3.745e-01, 8.942e-05],\n",
       "       [8.495e-03, 3.726e-01, 5.473e-01],\n",
       "       [9.838e-01, 4.621e-02, 5.153e-05],\n",
       "       [9.243e-01, 2.430e-02, 4.605e-04],\n",
       "       [3.368e-02, 3.010e-01, 1.268e-01],\n",
       "       [1.382e-01, 8.197e-01, 1.393e-02],\n",
       "       [9.354e-01, 7.653e-02, 1.890e-04],\n",
       "       [3.203e-03, 2.110e-01, 8.614e-01],\n",
       "       [2.356e-02, 3.362e-01, 4.225e-01],\n",
       "       [9.564e-01, 5.500e-02, 8.986e-05],\n",
       "       [8.626e-03, 2.552e-01, 6.562e-01],\n",
       "       [1.470e-03, 3.826e-01, 9.360e-01],\n",
       "       [5.621e-02, 5.457e-01, 1.260e-01],\n",
       "       [9.473e-01, 1.638e-02, 1.439e-04],\n",
       "       [5.462e-03, 5.319e-01, 6.328e-01],\n",
       "       [3.827e-02, 2.466e-01, 1.968e-01],\n",
       "       [4.839e-02, 5.697e-01, 6.242e-02],\n",
       "       [2.214e-03, 2.036e-01, 8.869e-01],\n",
       "       [9.610e-01, 1.536e-01, 6.943e-05],\n",
       "       [4.142e-03, 1.190e-01, 8.280e-01],\n",
       "       [9.309e-01, 5.427e-02, 3.116e-04],\n",
       "       [9.628e-01, 2.589e-02, 8.824e-05],\n",
       "       [7.879e-02, 9.288e-01, 1.752e-02],\n",
       "       [2.898e-03, 2.582e-01, 8.415e-01],\n",
       "       [1.490e-03, 8.604e-02, 9.751e-01],\n",
       "       [4.466e-03, 8.512e-01, 4.317e-01],\n",
       "       [1.061e-03, 6.411e-01, 8.594e-01],\n",
       "       [5.781e-02, 6.732e-01, 4.662e-02],\n",
       "       [6.067e-04, 1.504e-01, 9.565e-01],\n",
       "       [1.871e-02, 1.039e-01, 4.564e-01],\n",
       "       [6.050e-02, 7.431e-01, 3.766e-02],\n",
       "       [6.444e-03, 4.449e-01, 5.643e-01],\n",
       "       [6.341e-03, 4.187e-01, 5.362e-01],\n",
       "       [1.318e-02, 7.555e-01, 5.394e-01],\n",
       "       [4.143e-03, 6.051e-01, 6.367e-01],\n",
       "       [1.900e-02, 1.034e-01, 2.215e-01],\n",
       "       [4.179e-03, 2.194e-01, 8.049e-01],\n",
       "       [2.984e-02, 8.438e-02, 4.250e-01],\n",
       "       [9.293e-01, 2.114e-01, 1.168e-04],\n",
       "       [4.345e-03, 5.288e-01, 7.922e-01],\n",
       "       [3.508e-02, 5.290e-01, 1.413e-01],\n",
       "       [1.089e-01, 3.139e-01, 4.869e-02],\n",
       "       [4.178e-02, 6.763e-01, 8.938e-02],\n",
       "       [2.027e-02, 2.644e-01, 2.927e-01],\n",
       "       [1.362e-03, 1.296e-01, 9.141e-01],\n",
       "       [9.631e-01, 2.746e-02, 9.588e-05],\n",
       "       [9.703e-01, 2.963e-01, 4.296e-05],\n",
       "       [2.909e-03, 4.611e-01, 7.843e-01],\n",
       "       [4.947e-02, 2.957e-01, 1.325e-01],\n",
       "       [9.326e-01, 6.926e-02, 1.110e-04],\n",
       "       [9.761e-01, 2.082e-03, 1.767e-04],\n",
       "       [1.132e-02, 1.497e-01, 3.601e-01]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "510533cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\semin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "X = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "\n",
    "y = pd.Series(boston.target, name='MEDV')\n",
    "\n",
    "pd.concat([X, y], axis=1).head()\n",
    "X.join(y).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ced8d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\semin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MedAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>3.887985</td>\n",
       "      <td>36.423914</td>\n",
       "      <td>2.620000</td>\n",
       "      <td>0.263275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>4.249969</td>\n",
       "      <td>37.131807</td>\n",
       "      <td>3.338714</td>\n",
       "      <td>0.353276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR</th>\n",
       "      <td>3.808910</td>\n",
       "      <td>35.179805</td>\n",
       "      <td>2.470752</td>\n",
       "      <td>0.442346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>4.224227</td>\n",
       "      <td>36.842376</td>\n",
       "      <td>3.301340</td>\n",
       "      <td>0.360686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            MAE        MSE     MedAE        R2\n",
       "DecisionTreeRegressor  3.887985  36.423914  2.620000  0.263275\n",
       "LinearRegression       4.249969  37.131807  3.338714  0.353276\n",
       "LinearSVR              3.808910  35.179805  2.470752  0.442346\n",
       "Ridge                  4.224227  36.842376  3.301340  0.360686"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(boston.data)\n",
    "y = boston.target\n",
    "scores = {}\n",
    "model = {'DecisionTreeRegressor': DecisionTreeRegressor(random_state=0),\n",
    "         'LinearRegression': LinearRegression(),\n",
    "         'LinearSVR': LinearSVR(random_state=0),\n",
    "         'Ridge': Ridge(random_state=0)}\n",
    "\n",
    "for model_name, model in model.items():\n",
    "    scores[(model_name, 'MSE')] = abs(cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')).mean()\n",
    "    scores[(model_name, 'MAE')] = abs(cross_val_score(model, X, y, cv=5, scoring='neg_mean_absolute_error')).mean()\n",
    "    scores[(model_name, 'MedAE')] = abs(cross_val_score(model, X, y, cv=5, scoring='neg_median_absolute_error')).mean()\n",
    "    scores[(model_name, 'R2')] = cross_val_score(model, X, y, cv=5, scoring='r2').mean()\n",
    "    \n",
    "pd.Series(scores).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "67a04b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\semin\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\semin\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.937063</td>\n",
       "      <td>0.950704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.948357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      test_score  train_score\n",
       "BaggingClassifier       0.937063     0.950704\n",
       "KNeighborsClassifier    0.923077     0.948357"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target,\n",
    "                                                    random_state=66, stratify=cancer.target)\n",
    "# n_estimators 파라미터는 구축할 약한 모델의 수\n",
    "models = {'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "          'BaggingClassifier': BaggingClassifier(KNeighborsClassifier(), n_estimators=100, random_state=0)}\n",
    "scores={}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    scores[(model_name, 'train_score')] = model.score(X_train, y_train)\n",
    "    scores[(model_name, 'test_score')] = model.score(X_test, y_test)\n",
    "\n",
    "pd.Series(scores).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b9b8af0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9642857142857143\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# 연습 문제 10-5\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=0,\n",
    "                                                    stratify=iris.target)\n",
    "\n",
    "# models = {'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "#           'BaggingClassifier': BaggingClassifier(KNeighborsClassifier(), random_state=0, n_estimators=10,\n",
    "#                                                  max_features=0.7, max_samples=0.7)}\n",
    "# results = {}\n",
    "# for model_name, model in models.items():\n",
    "#     model.fit(X_train, y_train)\n",
    "#     results[(model_name, 'train_score')] = model.score(X_train, y_train)\n",
    "#     results[(model_name, 'test_score')] = model.score(X_test, y_test)\n",
    "# pd.Series(results).unstack()\n",
    "my_model = BaggingClassifier(KNeighborsClassifier(), random_state=0, n_estimators=10,\n",
    "                                                 max_features=0.5, max_samples=0.5)\n",
    "my_model.fit(X_train, y_train)\n",
    "print(my_model.score(X_train, y_train))\n",
    "print(my_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e7639593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\semin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.922829</td>\n",
       "      <td>0.999522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>0.721430</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          test_score  train_score\n",
       "AdaBoost    0.922829     0.999522\n",
       "tree        0.721430     1.000000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target,\n",
    "                                                   random_state=66)\n",
    "models = {'tree': DecisionTreeRegressor(random_state=0),\n",
    "          'AdaBoost': AdaBoostRegressor(DecisionTreeRegressor(), random_state=0)}\n",
    "\n",
    "scores={}\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    scores[(model_name, 'train_score')] = model.score(X_train, y_train)\n",
    "    scores[(model_name, 'test_score')] = model.score(X_test, y_test)\n",
    "    \n",
    "pd.Series(scores).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1a881304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9553571428571429\n",
      "0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# 연습 문제 10-6\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=0, stratify = iris.target)\n",
    "\n",
    "model = AdaBoostClassifier(n_estimators=50, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_train, y_train))\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9640cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\semin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.926076</td>\n",
       "      <td>0.977138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.894637</td>\n",
       "      <td>0.979374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               test     train\n",
       "GradientBoostingRegressor  0.926076  0.977138\n",
       "RandomForestRegressor      0.894637  0.979374"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target, random_state=66)\n",
    "\n",
    "models = {'RandomForestRegressor': RandomForestRegressor(random_state=0),\n",
    "          'GradientBoostingRegressor': GradientBoostingRegressor(random_state=0)}\n",
    "\n",
    "scores={}\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    scores[(model_name, 'train')] = model.score(X_train, y_train)\n",
    "    scores[(model_name, 'test')] = model.score(X_test, y_test)\n",
    "    \n",
    "pd.Series(scores).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3606877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = pd.Series(models['RandomForestRegressor'].feature_importances_, index = boston.feature_names)\n",
    "s.sort_values(ascending=False).plot.bar(color='C0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d09d1f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.973684</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.947368</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                test  train\n",
       "GradientBoostingClassifier  0.973684    1.0\n",
       "RandomForestClassifier      0.947368    1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 연습 문제 10-7\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=0, stratify=iris.target)\n",
    "\n",
    "models={'RandomForestClassifier': RandomForestClassifier(random_state=0),\n",
    "        'GradientBoostingClassifier': GradientBoostingClassifier(random_state=0)}\n",
    "\n",
    "accuracy = {}\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy[(model_name, 'train')] = model.score(X_train, y_train)\n",
    "    accuracy[(model_name, 'test')] = model.score(X_test, y_test)\n",
    "    \n",
    "pd.Series(accuracy).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d500629d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\semin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\semin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\semin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\semin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\semin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\semin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\semin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\semin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\semin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\semin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\semin\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\semin\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\semin\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\semin\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\semin\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model: RandomForestClassifier\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.961372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.927946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.947291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.963111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.920944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            mean_accuracy\n",
       "GradientBoostingClassifier       0.961372\n",
       "KNeighborsClassifier             0.927946\n",
       "LogisticRegression               0.947291\n",
       "RandomForestClassifier           0.963111\n",
       "SVM                              0.920944"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 종합문제 10-2\n",
    "# 유방암 데이터를 이용해 로지스틱 회귀, SVM, 의사결정나무, K-NN, 랜덤 포레스트, 그레이디언트 부스팅 등의 모델을 구축하고,\n",
    "# 교차검증(5겹) 방법으로 가장 좋은 모델을 선정해보기\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "models = {'LogisticRegression': LogisticRegression(random_state=0),\n",
    "          'SVM': LinearSVC(random_state=0),\n",
    "          'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "          'RandomForestClassifier': RandomForestClassifier(random_state=0),\n",
    "          'GradientBoostingClassifier': GradientBoostingClassifier(random_state=0)}\n",
    "\n",
    "accuracy = {}\n",
    "for model_name, model in models.items():\n",
    "    accuracy[(model_name, 'mean_accuracy')] = cross_val_score(model, cancer.data, cancer.target, cv=5).mean()\n",
    "    \n",
    "print(f\"best model: {pd.Series(accuracy).unstack()['mean_accuracy'].idxmax()}\")\n",
    "pd.Series(accuracy).unstack()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
